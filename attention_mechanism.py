# -*- coding: utf-8 -*-
"""attention mechanism.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KzWAH1IwK-MKJELDHBaBxyaCozGjx56K
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf

def attention_module(input_tensor):
    # Apply global average pooling to reduce spatial dimensions
    x = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)

    # Reshape to match the number of filters
    x = tf.keras.layers.Reshape((1, 1, x.shape[-1]))(x)

    # Apply convolutional layers
    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(1, 1), activation='relu')(x)
    x = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(x)

    # Multiply the attention weights with the input tensor
    attention = tf.keras.layers.Multiply()([input_tensor, x])

    # Add the attention to the original input tensor
    output_tensor = tf.keras.layers.Add()([input_tensor, attention])

    return output_tensor

def DnCNN_with_Attention():
    input_img = tf.keras.layers.Input(shape=(1000, 1000, 3))

    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_img)
    x = tf.keras.layers.ReLU()(x)

    # Apply attention mechanism
    x = attention_module(x)

    for i in range(15):
        x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.ReLU()(x)

        # Apply attention mechanism after each convolutional layer
        x = attention_module(x)

    output_img = tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), padding='same')(x)
    model = tf.keras.Model(inputs=input_img, outputs=output_img)

    return model

import numpy as np
import os, cv2
# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# train_datagen = ImageDataGenerator(rescale=1./255)

# train_generator = train_datagen.flow_from_directory(
#     '/content/drive/MyDrive/AutoEncoderData/images_sattelite/',
#     target_size=(1500, 1500),
#     batch_size=2,
#     class_mode='input',
#     classes=['clean', 'noise']
# )

# set the image size for resizing
img_size = (1000, 1000)

# set the directories for the input and output images
input_dir = '/content/drive/MyDrive/AutoEncoderData new/images_sattelite/noise/train'
output_dir = '/content/drive/MyDrive/AutoEncoderData new/images_sattelite/clean/train'

# initialize arrays for the input and output images
input_image = []
output_image = []

# read input images from the input directory
for filename in sorted(os.listdir(input_dir)):
    img = cv2.imread(os.path.join(input_dir, filename))
    img = cv2.resize(img, img_size)
    img = img.astype('float32') / 255.0
    input_image.append(img)

# read output images from the output directory
for filename in sorted(os.listdir(output_dir)):
    img = cv2.imread(os.path.join(output_dir, filename))
    img = cv2.resize(img, img_size)
    img = img.astype('float32') / 255.0
    output_image.append(img)

# convert the input and output arrays to numpy arrays
input_image = np.array(input_image)
output_image = np.array(output_image)

print(input_image.shape)
print(output_image.shape)

from tensorflow.keras.callbacks import ModelCheckpoint

# Define the checkpoint filename and path
checkpoint_path = "/content/drive/MyDrive/AutoEncoderData new/Good.h5"

# Create a ModelCheckpoint callback that saves the model weights after each epoch
checkpoint_callback = ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=False,
    save_best_only=False,
    verbose=1,
)

# Create the model
model = DnCNN_with_Attention()

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Display model summary
model.summary()

history = model.fit(input_image, output_image, batch_size=2, epochs=50, callbacks=[checkpoint_callback])

import matplotlib.pyplot as plt

plt.plot(history.history["loss"], label="losses per epoch")

import numpy as np
print("Average Loss:",np.mean(history.history["loss"]))

from tensorflow.keras.models import load_model
model = load_model("/content/drive/MyDrive/AutoEncoderData/Good.h5")

import tensorflow as tf

def preprocess_input(x):
    """Preprocesses a NumPy array representing an image for use with the DnCNN model."""
    x = x / 255.0  # Normalize pixel values to [0, 1]
    return x

def postprocess_output(y):
    """Converts the output of the DnCNN model to a denoised image."""
    y = y * 255.0  # Scale pixel values back to [0, 255]
    y = tf.clip_by_value(y, 0.0, 255.0)  # Clip values to [0, 255] to ensure valid pixel range
    y = tf.cast(y, tf.uint8)  # Convert pixel values to integers in [0, 255]
    y = tf.squeeze(y, axis=0)  # Remove batch dimension
    y = y.numpy()  # Convert tensor to NumPy array
    return y

from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

img = load_img('/content/drive/MyDrive/AutoEncoderData/images_sattelite/images_sattelite/noise/22828945_15.png', target_size=(1000, 1000))
x = img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
y_pred = model.predict(x)
y_pred = postprocess_output(y_pred)

import matplotlib.pyplot as plt
plt.imshow(img)
plt.title('Input Image')
plt.show()

plt.imshow(y_pred)
plt.title('Model Output')
plt.show()

!mkdir /content/drive/MyDrive/AutoEncoderData/result02

import glob, cv2
for img_path in glob.glob("/content/drive/MyDrive/AutoEncoderData/images_sattelite/images_sattelite/noise/*"):
  img = load_img(img_path, target_size=(1000, 1000))
  x = img_to_array(img)
  x = np.expand_dims(x, axis=0)
  x = preprocess_input(x)
  y_pred = model.predict(x)
  y_pred = postprocess_output(y_pred)
  plt.imshow(y_pred)
  y_pred = cv2.cvtColor(y_pred, cv2.COLOR_BGR2RGB)
  cv2.imwrite("/content/drive/MyDrive/AutoEncoderData/result02/" + img_path.split("/")[-1], y_pred)
  plt.show()